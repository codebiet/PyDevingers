{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "TRAINING_DIR = \"/Users/prabh/Downloads/mymodel2/mymodel2\"\n",
    "image_generator = ImageDataGenerator(rescale = 1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = image_generator.flow_from_directory(\n",
    "        TRAINING_DIR,\n",
    "        target_size=(100,100),\n",
    "        class_mode='categorical',\n",
    "        batch_size=32\n",
    ")\n",
    "label_map = (train_generator.class_indices)\n",
    "\n",
    "validation_generator = image_generator.flow_from_directory(\n",
    "        TRAINING_DIR,\n",
    "        target_size=(100,100),\n",
    "        class_mode='categorical',\n",
    "  batch_size=32\n",
    ")\n",
    "def md():\n",
    "    import tensorflow as tf\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(100, 100, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2), \n",
    "        # tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n",
    "        # tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n",
    "        # tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # Flatten the results to feed into a DNN\n",
    "        tf.keras.layers.Flatten(), \n",
    "        # 512 neuron hidden layer\n",
    "        tf.keras.layers.Dense(514, activation='relu'), \n",
    "        tf.keras.layers.Dense(214, activation='relu'), \n",
    "        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
    "        tf.keras.layers.Dense(29, activation='softmax')  \n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_generator,\n",
    "                                  validation_data=validation_generator,\n",
    "                                  steps_per_epoch=1700,\n",
    "                                  epochs=5,\n",
    "                              validation_steps=50,\n",
    "                              verbose=1)\n",
    "\n",
    "    model.save(\"mymodel2\")\n",
    "\n",
    "md()\n",
    "\n",
    "model = keras.models.load_model(\"mymodel2\")\n",
    "\n",
    "stream=cv2.VideoCapture(0)\n",
    "\n",
    "def get_key(val):\n",
    "    for key, value in label_map.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\"\n",
    " \n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=1)\n",
    "  # resize the image to the desired size\n",
    "  return tf.image.resize(img, [28, 28])\n",
    "\n",
    "\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "# backSub = cv2.createBackgroundSubtractorKNN()\n",
    "while True:\n",
    "    ret, frame=stream.read()\n",
    "\n",
    "    cv2.rectangle(frame, (100, 100), (500, 500), (0, 255,0),6)\n",
    "    frame2=cv2.flip(frame, 1)\n",
    "    cv2.imshow('video', frame2)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    hand_frame = frame[100:500, 100:500]\n",
    "    fgMask = backSub.apply(hand_frame)\n",
    "\n",
    "    cv2.imshow('Video', hand_frame)\n",
    "    cv2.imshow('fg mask', fgMask)\n",
    "\n",
    "    # image_np = np.array(frame)\n",
    "    # img = decode_img(image_np)\n",
    "    inp = cv2.resize(hand_frame, (100 , 100 ))\n",
    "    # asdf = cv2.cvtColor(inp, cv2.COLOR_BGR2GRAY)\n",
    "    asdf = cv2.cvtColor(inp, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Is optional but i recommend (float convertion and convert img to tensor image)\n",
    "    rgb_tensor = tf.convert_to_tensor(asdf, dtype=tf.float32)\n",
    "\n",
    "    #Add dims to rgb_tensor\n",
    "    rgb_tensor = tf.expand_dims(rgb_tensor , 0)\n",
    "\n",
    "\n",
    "\n",
    "    classes = model.predict(rgb_tensor, steps=1)\n",
    "    # print(classes)\n",
    "    # print(classes[0])\n",
    "    print(np.argmax(classes[0]))\n",
    "    print(get_key(np.argmax(classes[0])))\n",
    "\n",
    "\n",
    "stream.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
